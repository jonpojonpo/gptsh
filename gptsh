#!/usr/bin/env python

import openai
import argparse
import json
from dotenv import load_dotenv
from prompt_toolkit import prompt
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory

import os
from gpt_functions import functions, get_function, get_function_schema, get_available_functions

# Load the API key
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
user = os.getenv("USER")
if not api_key:
    print("Error: API Key not found in .env file")
    exit(1)


def load_system_prompt(prompt_name):
    with open(f'system_prompts/{prompt_name}.txt', 'r') as prompt_file:
        return prompt_file.read()


def main():
    load_dotenv()
    # Get the API key
    api_key = os.getenv("OPENAI_API_KEY")
    available_functions = get_available_functions()
    #Create a dictionary with function schemas
    function_schemas = {name: get_function_schema(name) for name in available_functions}
    parser = argparse.ArgumentParser(description='Chat with OpenAI GPT.')

    parser.add_argument('--model', type=str, default='gpt-3.5-turbo-0613',
                        help='The model to be used by OpenAI GPT.')
    #parser.add_argument('--prompt', type=str, default='The AlphaMind is ready:',
    #                    help='The initial prompt to use for the conversation.')
    parser.add_argument('--prompt-file', type=str, default='AlphaMind',
                        help='The name of the prompt-file to use for the conversation.')
    parser.add_argument('--functions', nargs='+', choices=available_functions, default=available_functions,
                        help='The functions to be loaded. Options: ' + ', '.join(available_functions))    
    args = parser.parse_args()

    # Load the selected functions
    functions = {f: get_function(f) for f in args.functions}
    function_schemas = [ get_function_schema(f) for f in args.functions]
    model = args.model
    sysprompt = load_system_prompt(args.prompt_file) 
    user_prompt = user + "> "
    prompt_history = FileHistory(".gptsh_history")
    session = PromptSession(history=prompt_history)

    # Start the conversation
    messages = [{'role': 'system', 'content': sysprompt}]

    print(f"{sysprompt}\n")

    while True:
        try:
            user_input = session.prompt(user_prompt)
            if user_input.lower() in ["exit", "quit"]:
                print("Exiting.")
                break

            messages.append({'role': 'user', 'content': user_input})

            print("Sending request to OpenAI")
            print(function_schemas)
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                functions=function_schemas,
                function_call="auto"
            )
            print("Received response from OpenAI")

            response_message = response["choices"][0]["message"]
            print(response_message)

            # Check if GPT wanted to call a function
            if 'function_call' in response_message:
                print("Function call requested")
                function_name = response_message["function_call"]["name"]
                print(f"Function name: {function_name}")
                function_to_call = get_function(function_name)
                arguments = response_message["function_call"]["arguments"]
                print(f"Raw arguments: {arguments}")

                # Assuming the arguments contain the code to be executed directly
                arguments = json.loads(arguments) 
                function_response = function_to_call(**arguments)
                # Function response might be a number or any other data type
                # Convert it to string before appending it to messages.
                print(f"Function response: {function_response}")
                function_response = str(function_response)

                # Append function response
                messages.append({
                    "role": "function",
                    "name": function_name,
                    "content": function_response,
                })

                # Make an additional call to OpenAI API with function response
                print("Sending second request to OpenAI with function response")
                second_response = openai.ChatCompletion.create(
                    model=model,
                    messages=messages,
                    functions=function_schemas
                )
                print("Received second response from OpenAI")

                # Get the assistant's message from the second response
                assistant_second_message = second_response["choices"][0]["message"]
                print(f"{model}> {assistant_second_message['content']}")

            else:
                print(f"{model}> {response_message['content']}")

        except KeyboardInterrupt:
            print("\nExiting.")
            break
        except Exception as e:
            print(f"An error occurred: {e}")

if __name__ == "__main__":
    main()

